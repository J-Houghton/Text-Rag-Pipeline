{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd23886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and configuration\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "from openai import OpenAI\n",
    "\n",
    "# Configure from env   \n",
    "load_dotenv()\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "OPENAI_API_KEY_CHAT = os.getenv(\"OPENAI_API_KEY_CHAT\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\", \"MyDocs\")\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\") \n",
    "\n",
    "# KMeans settings\n",
    "N_CLUSTERS = 60  # tune this\n",
    "MAX_OBJECTS = None  # or an int to cap total objects fetched\n",
    "\n",
    "# Weaviate fetch settings\n",
    "PAGE_LIMIT = 200  # objects per page\n",
    "\n",
    "# OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY_CHAT)\n",
    "\n",
    "weaviate_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {WEAVIATE_API_KEY}\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9445b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(cursor: str = None, limit: int = PAGE_LIMIT) -> List[Dict[str, Any]]:\n",
    "    after_clause = f'after: \"{cursor}\"' if cursor else \"\"\n",
    "    query = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          Get {{\n",
    "            {COLLECTION_NAME}(\n",
    "              limit: {limit}\n",
    "              {after_clause}\n",
    "            ) {{\n",
    "              chunk_id\n",
    "              doc_id\n",
    "              text\n",
    "              _additional {{\n",
    "                id\n",
    "                vectors {{\n",
    "                  default\n",
    "                }}\n",
    "              }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    resp = requests.post(\n",
    "        f\"{WEAVIATE_URL}/v1/graphql\",\n",
    "        json=query,\n",
    "        headers=weaviate_headers,\n",
    "        timeout=60,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    if \"errors\" in data:\n",
    "        raise RuntimeError(f\"Weaviate GraphQL error: {data['errors']}\")\n",
    "\n",
    "    objects = data[\"data\"][\"Get\"][COLLECTION_NAME]\n",
    "    return objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03c3b62",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Weaviate GraphQL error: [{'locations': [{'column': 17, 'line': 13}], 'message': 'Cannot query field \"vectors\" on type \"MyDocsCleanedAdditional\". Did you mean \"vector\"?', 'path': None}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m cursor = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     rows = \u001b[43mfetch_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPAGE_LIMIT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rows:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 36\u001b[39m, in \u001b[36mfetch_page\u001b[39m\u001b[34m(cursor, limit)\u001b[39m\n\u001b[32m     33\u001b[39m data = resp.json()\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWeaviate GraphQL error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata[\u001b[33m'\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m objects = data[\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mGet\u001b[39m\u001b[33m\"\u001b[39m][COLLECTION_NAME]\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m objects\n",
      "\u001b[31mRuntimeError\u001b[39m: Weaviate GraphQL error: [{'locations': [{'column': 17, 'line': 13}], 'message': 'Cannot query field \"vectors\" on type \"MyDocsCleanedAdditional\". Did you mean \"vector\"?', 'path': None}]"
     ]
    }
   ],
   "source": [
    "# Cell 3: Pull all chunks + embeddings into a DataFrame \n",
    "all_rows = []\n",
    "cursor = None\n",
    "\n",
    "while True:\n",
    "    rows = fetch_page(cursor, PAGE_LIMIT)\n",
    "    if not rows:\n",
    "        break\n",
    "\n",
    "    all_rows.extend(rows)\n",
    "    cursor = rows[-1][\"_additional\"][\"id\"]  # use last id as cursor\n",
    "\n",
    "    print(f\"Fetched {len(all_rows)} objects so far...\")\n",
    "\n",
    "    if MAX_OBJECTS is not None and len(all_rows) >= MAX_OBJECTS:\n",
    "        all_rows = all_rows[:MAX_OBJECTS]\n",
    "        print(f\"Reached MAX_OBJECTS={MAX_OBJECTS}, stopping fetch.\")\n",
    "        break\n",
    "\n",
    "print(f\"Total fetched from Weaviate: {len(all_rows)}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "records = []\n",
    "for r in all_rows:\n",
    "    add = r[\"_additional\"]\n",
    "    props = {\n",
    "        \"_id\": add[\"id\"],\n",
    "        \"embedding\": add[\"vectors\"][\"default\"],\n",
    "        \"chunk_id\": r.get(\"chunk_id\"),\n",
    "        \"doc_id\": r.get(\"doc_id\"),\n",
    "        \"text\": r.get(\"text\"),\n",
    "    }\n",
    "    records.append(props)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "\n",
    "# Build embedding matrix\n",
    "X = np.array(df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "print(\"Embeddings shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb4337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized embeddings shape: (51088, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Normalize embeddings for cosine-like distance\n",
    "\n",
    "# L2 normalize rows so dot product approximates cosine similarity\n",
    "X_norm = normalize(X, norm=\"l2\", axis=1)\n",
    "print(\"Normalized embeddings shape:\", X_norm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a05d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_id\n",
      "7     3141\n",
      "57    1787\n",
      "22    1554\n",
      "0     1428\n",
      "45    1387\n",
      "Name: count, dtype: int64\n",
      "Number of clusters with at least one point: 60\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: KMeans clustering\n",
    "\n",
    "kmeans = KMeans(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    random_state=42,\n",
    "    n_init=10,\n",
    ")\n",
    "\n",
    "cluster_ids = kmeans.fit_predict(X_norm)\n",
    "df[\"cluster_id\"] = cluster_ids\n",
    "\n",
    "print(df[\"cluster_id\"].value_counts().head())\n",
    "print(\"Number of clusters with at least one point:\", df[\"cluster_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fe970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Helper to get representative texts per cluster\n",
    "\n",
    "def get_representatives_for_cluster(cluster_id: int, top_k: int = 30) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return up to top_k representative texts from a given cluster, ordered by\n",
    "    similarity to the cluster centroid.\n",
    "    \"\"\"\n",
    "    mask = df[\"cluster_id\"] == cluster_id\n",
    "    idx = np.where(mask.values)[0]\n",
    "\n",
    "    if len(idx) == 0:\n",
    "        return []\n",
    "\n",
    "    cluster_vectors = X_norm[idx]\n",
    "    centroid = kmeans.cluster_centers_[cluster_id]\n",
    "\n",
    "    # similarity scores = dot product with centroid\n",
    "    scores = cluster_vectors @ centroid\n",
    "    order = np.argsort(-scores)\n",
    "    top_idx = idx[order[:top_k]]\n",
    "\n",
    "    reps = df.loc[top_idx, \"text\"].astype(str).tolist()\n",
    "    return reps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d31fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: OpenAI helper to label clusters\n",
    "\n",
    "def llm_label_cluster(cluster_id: int, example_texts: List[str], max_chars: int = 4000):\n",
    "    \"\"\"\n",
    "    Ask OpenAI to propose a short name and summary for a cluster, given example texts.\n",
    "    Returns (cluster_name, cluster_summary).\n",
    "    \"\"\"\n",
    "    if not example_texts:\n",
    "        return \"Unknown\", \"No examples available for this cluster.\"\n",
    "\n",
    "    combined = \"\\n\\n\".join(example_texts)\n",
    "    combined = combined[:max_chars]\n",
    "\n",
    "    system_msg = (\n",
    "        \"You receive multiple paragraphs that belong to one semantic cluster produced by KMeans.\\n\"\n",
    "        \"Task:\\n\"\n",
    "        \"1. Produce a short descriptive cluster name, max 8 words.\\n\"\n",
    "        \"2. Produce a concise summary of the main theme, exactly 3 sentences.\\n\"\n",
    "        \"3. Output must be valid JSON with keys: cluster_name, cluster_summary.\"\n",
    "        \"\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"- Base your name and summary only on the provided paragraphs.\\n\"\n",
    "        \"- Prefer specificity over vague themes.\\n\"\n",
    "    )\n",
    "\n",
    "    user_msg = f\"Cluster ID: {cluster_id}\\n\\nExample paragraphs:\\n\\n{combined}\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    data = json.loads(resp.choices[0].message.content)\n",
    "    cluster_name = data.get(\"cluster_name\", f\"Cluster {cluster_id}\")\n",
    "    cluster_summary = data.get(\"cluster_summary\", \"\")\n",
    "    return cluster_name, cluster_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0da3b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> Confidential Communication and Planning\n",
      "1 -> Real Estate Transaction Records\n",
      "2 -> Exploitation and Abuse at Epstein's Ranch\n",
      "3 -> Israeli-Palestinian Conflict Dynamics\n",
      "4 -> Confidential Communication and Privilege Notice\n",
      "5 -> Market Sentiment on Financial Stocks\n",
      "6 -> Power Dynamics in Digital Networks\n",
      "7 -> Condominium Sales Data\n",
      "8 -> Victims' Rights in Criminal Justice\n",
      "9 -> Social Connections and Beliefs\n",
      "10 -> Global Regulatory Landscape of Cannabis\n",
      "11 -> China's Global Influence Strategies\n",
      "12 -> Residential Data Transactions\n",
      "13 -> Challenges and Reflections on Artificial Intelligence\n",
      "14 -> Sexual Misconduct Allegations Against Krauss\n",
      "15 -> Prominent Leaders in Business and Academia\n",
      "16 -> Underage Massage Encounters\n",
      "17 -> Youth Disillusionment and Parental Conflict\n",
      "18 -> Epstein's Legal Proceedings and Victims' Rights\n",
      "19 -> Taboo-Breaking Comedy and Social Commentary\n",
      "20 -> Exploring BDSM and Sexual Consent\n",
      "21 -> Tax Policy and Economic Trends\n",
      "22 -> Email Campaign Tracking and Engagement\n",
      "23 -> Communication and Human Understanding\n",
      "24 -> Edward Snowden and NSA Leaks\n",
      "25 -> Legal Actions Against Terrorism Supporters\n",
      "26 -> Marina Property Market Analysis\n",
      "27 -> Epstein's Power and Public Persona\n",
      "28 -> Workplace Notice Posting and Employee Rights\n",
      "29 -> Elderly Technology and GPS Solutions\n",
      "30 -> Exploitation and Ambition in Massage Therapy\n",
      "31 -> Middle East Geopolitical Dynamics\n",
      "32 -> FCPA Compliance and Anti-Corruption Measures\n",
      "33 -> Cooperative Apartments and Property Listings\n",
      "34 -> Brexit Social Media Discussions\n",
      "35 -> Trump Organization Shareholder Structure\n",
      "36 -> Confidential Communication Notices\n",
      "37 -> Global Economic Outlook and Investment Strategies\n",
      "38 -> Investment Risk and Financial Projections\n",
      "39 -> Legal Proceedings and Victims' Rights\n",
      "40 -> House Oversight Investigations\n",
      "41 -> Communications Regarding Trump and Associates\n",
      "42 -> Legal Discussions on Epstein Allegations\n",
      "43 -> Financial Oversight and Personal Matters\n",
      "44 -> Dynamics and Chaos in Neuroscience\n",
      "45 -> Casual Email Communication\n",
      "46 -> Property Transactions in Palm Beach\n",
      "47 -> Bannon's Role in Trump's Presidency\n",
      "48 -> Law Enforcement Operations and Procedures\n",
      "49 -> Trump Administration Legal and Political Challenges\n",
      "50 -> AGI Cognitive Architecture and Theories\n",
      "51 -> Legal Ethics and Defense Tactics\n",
      "52 -> Financial Advisory and Research Disclaimers\n",
      "53 -> Military Reflections on the Six-Day War\n",
      "54 -> Israeli-Palestinian Peace Negotiations\n",
      "55 -> Investment and Human Capital Dynamics\n",
      "56 -> Celebrity Encounters and Red Carpet Events\n",
      "57 -> High-Value Single Family Properties\n",
      "58 -> Saudi Arabia's Economic Diversification Challenges\n",
      "59 -> Innovative Approaches to Education\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>cluster_summary</th>\n",
       "      <th>num_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Confidential Communication and Planning</td>\n",
       "      <td>These paragraphs include personal communicatio...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Real Estate Transaction Records</td>\n",
       "      <td>This cluster contains data outlining various r...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Exploitation and Abuse at Epstein's Ranch</td>\n",
       "      <td>The paragraphs detail Jeffrey Epstein's system...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Israeli-Palestinian Conflict Dynamics</td>\n",
       "      <td>The text discusses the evolving threats faced ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Confidential Communication and Privilege Notice</td>\n",
       "      <td>The paragraphs emphasize the confidentiality o...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id                                     cluster_name  \\\n",
       "0           0          Confidential Communication and Planning   \n",
       "1           1                  Real Estate Transaction Records   \n",
       "2           2        Exploitation and Abuse at Epstein's Ranch   \n",
       "3           3            Israeli-Palestinian Conflict Dynamics   \n",
       "4           4  Confidential Communication and Privilege Notice   \n",
       "\n",
       "                                     cluster_summary  num_examples  \n",
       "0  These paragraphs include personal communicatio...            25  \n",
       "1  This cluster contains data outlining various r...            25  \n",
       "2  The paragraphs detail Jeffrey Epstein's system...            25  \n",
       "3  The text discusses the evolving threats faced ...            25  \n",
       "4  The paragraphs emphasize the confidentiality o...            25  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 8: Label all clusters with OpenAI\n",
    "\n",
    "cluster_labels = []\n",
    "max_examples_per_cluster = 25  # tune for cost / quality\n",
    "\n",
    "for cid in sorted(df[\"cluster_id\"].unique()):\n",
    "    examples = get_representatives_for_cluster(cid, top_k=max_examples_per_cluster)\n",
    "    if not examples:\n",
    "        cluster_name = f\"Cluster {cid}\"\n",
    "        cluster_summary = \"No representative examples available.\"\n",
    "    else:\n",
    "        cluster_name, cluster_summary = llm_label_cluster(cid, examples)\n",
    "\n",
    "    cluster_labels.append(\n",
    "        {\n",
    "            \"cluster_id\": cid,\n",
    "            \"cluster_name\": cluster_name,\n",
    "            \"cluster_summary\": cluster_summary,\n",
    "            \"num_examples\": len(examples),\n",
    "        }\n",
    "    )\n",
    "    print(cid, \"->\", cluster_name)\n",
    "\n",
    "cluster_labels_df = pd.DataFrame(cluster_labels)\n",
    "cluster_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a4f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      chunk_id  doc_id  cluster_id  \\\n",
      "0  016552_c680  016552          33   \n",
      "1  023361_c103  023361          25   \n",
      "2  028621_c044  028621          15   \n",
      "3  016221_c286  016221           9   \n",
      "4  016697_c495  016697          12   \n",
      "\n",
      "                                   cluster_name  \n",
      "0  Cooperative Apartments and Property Listings  \n",
      "1    Legal Actions Against Terrorism Supporters  \n",
      "2    Prominent Leaders in Business and Academia  \n",
      "3                Social Connections and Beliefs  \n",
      "4                 Residential Data Transactions  \n",
      "Saved CSV: chunks_with_kmeans_clusters_and_labels_from_weaviate_FULL.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Join labels back to df and optionally save locally\n",
    "\n",
    "df = df.merge(cluster_labels_df, on=\"cluster_id\", how=\"left\")\n",
    "\n",
    "print(df[[\"chunk_id\", \"doc_id\", \"cluster_id\", \"cluster_name\"]].head())\n",
    "\n",
    "# Optional: save to CSV for inspection\n",
    "df.to_csv(\"chunks_with_kmeans_clusters_and_labels_from_weaviate_FULL.csv\", index=False)\n",
    "print(\"Saved CSV: chunks_with_kmeans_clusters_and_labels_from_weaviate_FULL.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
