{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd23886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Imports and configuration\n",
    "\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from openai import OpenAI\n",
    "\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ----- load env -----\n",
    "load_dotenv()\n",
    "\n",
    "WEAVIATE_URL = os.getenv(\"WEAVIATE_URL\")           # e.g. https://xxx.weaviate.network\n",
    "WEAVIATE_API_KEY = os.getenv(\"WEAVIATE_API_KEY\")\n",
    "COLLECTION_NAME = os.getenv(\"COLLECTION_NAME\", \"MyDocs\")\n",
    "\n",
    "OPENAI_API_KEY_CHAT = os.getenv(\"OPENAI_API_KEY_CHAT\")       # chat model key for labeling\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")       # chat model key for labeling \n",
    "\n",
    "assert WEAVIATE_URL and WEAVIATE_API_KEY, \"Weaviate env vars missing\"\n",
    "assert OPENAI_API_KEY_CHAT, \"OPENAI_API_KEY_CHAT missing\"\n",
    "\n",
    "# Optional cap while experimenting; set to None for full ~50k\n",
    "MAX_OBJECTS = 5000    # e.g. 5000 for testing, then None\n",
    "\n",
    "# Weaviate fetch settings\n",
    "PAGE_LIMIT = 500      # objects per page\n",
    "\n",
    "# UMAP settings (clustering space)\n",
    "UMAP_N_COMPONENTS = 5\n",
    "UMAP_N_NEIGHBORS = 15\n",
    "UMAP_MIN_DIST = 0.0\n",
    "\n",
    "# HDBSCAN settings\n",
    "HDBSCAN_MIN_CLUSTER_SIZE = 50   # tune for your corpus size\n",
    "HDBSCAN_MIN_SAMPLES = 10\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY_CHAT)\n",
    "\n",
    "weaviate_headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {WEAVIATE_API_KEY}\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9445b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Helper to fetch pages from Weaviate (GraphQL)\n",
    "\n",
    "def fetch_page(cursor: str = None, limit: int = PAGE_LIMIT) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Fetch one page of objects (with embeddings) from Weaviate using GraphQL.\n",
    "    Returns a list of objects with properties and _additional fields.\n",
    "    \"\"\"\n",
    "    after_clause = f'after: \"{cursor}\"' if cursor else \"\"\n",
    "    query = {\n",
    "        \"query\": f\"\"\"\n",
    "        {{\n",
    "          Get {{\n",
    "            {COLLECTION_NAME}(\n",
    "              limit: {limit}\n",
    "              {after_clause}\n",
    "            ) {{\n",
    "              chunk_id\n",
    "              doc_id\n",
    "              text\n",
    "              _additional {{\n",
    "                id\n",
    "                vectors {{\n",
    "                  default\n",
    "                }}\n",
    "              }}\n",
    "            }}\n",
    "          }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "    }\n",
    "\n",
    "    resp = requests.post(\n",
    "        f\"{WEAVIATE_URL}/v1/graphql\",\n",
    "        json=query,\n",
    "        headers=weaviate_headers,\n",
    "        timeout=60,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    if \"errors\" in data:\n",
    "        raise RuntimeError(f\"Weaviate GraphQL error: {data['errors']}\")\n",
    "\n",
    "    return data[\"data\"][\"Get\"][COLLECTION_NAME]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03c3b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 500 objects so far...\n",
      "Fetched 1000 objects so far...\n",
      "Fetched 1500 objects so far...\n",
      "Fetched 2000 objects so far...\n",
      "Fetched 2500 objects so far...\n",
      "Fetched 3000 objects so far...\n",
      "Fetched 3500 objects so far...\n",
      "Fetched 4000 objects so far...\n",
      "Fetched 4500 objects so far...\n",
      "Fetched 5000 objects so far...\n",
      "Reached MAX_OBJECTS=5000, stopping fetch.\n",
      "Total fetched from Weaviate: 5000\n",
      "                                    _id  \\\n",
      "0  000203a2-f584-43f1-8527-e167b0bf8c6e   \n",
      "1  00046a59-5d95-4bdd-9bef-2acc2feead61   \n",
      "2  0008b585-596a-42b9-8d0a-9be00a32b994   \n",
      "3  00091260-d45d-4f44-bb4e-8100c280de0e   \n",
      "4  00099043-8c80-4015-8d4c-6912225c5d60   \n",
      "\n",
      "                                           embedding     chunk_id  doc_id  \\\n",
      "0  [-0.006832002, 0.058254257, 0.033376772, 0.006...  016697_c937  016697   \n",
      "1  [-0.0023835688, 0.040449306, 0.038565286, 0.02...  023731_c153  023731   \n",
      "2  [-0.028839508, -0.014247406, -0.013418496, 0.0...  027333_c015  027333   \n",
      "3  [0.042262483, 0.022982152, 0.054571044, 0.0609...  025231_c005  025231   \n",
      "4  [0.015008055, -0.00056260754, -0.024414347, 0....  017088_c153  017088   \n",
      "\n",
      "                                                text  \n",
      "0  0024-001 3181903 0 3181903 RES N 50-43-43-10-1...  \n",
      "1   scholars. But, in a way, he was very wrong. Y...  \n",
      "2  5 Is Read: Yes Is Invitation: No GUID: 734F669...  \n",
      "3  -mail message is subject to the Dubai World Gr...  \n",
      "4   for a return of McCarthyism or for military h...  \n",
      "DataFrame shape: (5000, 5)\n",
      "Embedding matrix shape: (5000, 1536)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Pull all chunks + embeddings into DataFrame\n",
    "\n",
    "all_rows = []\n",
    "cursor = None\n",
    "\n",
    "while True:\n",
    "    rows = fetch_page(cursor, PAGE_LIMIT)\n",
    "    if not rows:\n",
    "        break\n",
    "\n",
    "    all_rows.extend(rows)\n",
    "    cursor = rows[-1][\"_additional\"][\"id\"]\n",
    "\n",
    "    print(f\"Fetched {len(all_rows)} objects so far...\")\n",
    "\n",
    "    if MAX_OBJECTS is not None and len(all_rows) >= MAX_OBJECTS:\n",
    "        all_rows = all_rows[:MAX_OBJECTS]\n",
    "        print(f\"Reached MAX_OBJECTS={MAX_OBJECTS}, stopping fetch.\")\n",
    "        break\n",
    "\n",
    "print(f\"Total fetched from Weaviate: {len(all_rows)}\")\n",
    "\n",
    "records = []\n",
    "for r in all_rows:\n",
    "    add = r[\"_additional\"]\n",
    "    records.append(\n",
    "        {\n",
    "            \"_id\": add[\"id\"],\n",
    "            \"embedding\": add[\"vectors\"][\"default\"],\n",
    "            \"chunk_id\": r.get(\"chunk_id\"),\n",
    "            \"doc_id\": r.get(\"doc_id\"),\n",
    "            \"text\": r.get(\"text\"), \n",
    "        }\n",
    "    )\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "\n",
    "X = np.array(df[\"embedding\"].tolist(), dtype=np.float32)\n",
    "print(\"Embedding matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb4337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done normalization.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Normalize embeddings (for cosine-like behavior)\n",
    "\n",
    "X_norm = normalize(X, norm=\"l2\", axis=1)\n",
    "print(\"Done normalization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a05d1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Downloads\\temp\\chunk\\venv\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP output shape: (5000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: UMAP projection to low-dimensional clustering space\n",
    "\n",
    "umap_model = umap.UMAP(\n",
    "    n_components=UMAP_N_COMPONENTS,\n",
    "    n_neighbors=UMAP_N_NEIGHBORS,\n",
    "    min_dist=UMAP_MIN_DIST,\n",
    "    metric=\"euclidean\",      # on normalized vectors this approximates cosine\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "X_umap = umap_model.fit_transform(X_norm)\n",
    "print(\"UMAP output shape:\", X_umap.shape)\n",
    "\n",
    "# Optional: store in df for later visualization if you want\n",
    "for i in range(UMAP_N_COMPONENTS):\n",
    "    df[f\"umap_{i}\"] = X_umap[:, i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89fe970d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster_id\n",
      "-1     752\n",
      " 17    477\n",
      " 1     326\n",
      " 10    309\n",
      " 5     281\n",
      " 27    254\n",
      " 21    250\n",
      " 2     186\n",
      " 22    176\n",
      " 3     143\n",
      " 24    119\n",
      " 26    114\n",
      " 13    110\n",
      " 28    109\n",
      " 4     109\n",
      " 15    107\n",
      " 20    104\n",
      " 25    102\n",
      " 18    100\n",
      " 11     98\n",
      "Name: count, dtype: int64\n",
      "Number of clusters (excluding noise): 30\n",
      "Number of noise points (label -1): 752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jake\\Downloads\\temp\\chunk\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Jake\\Downloads\\temp\\chunk\\venv\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: HDBSCAN clustering\n",
    "\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=HDBSCAN_MIN_CLUSTER_SIZE,\n",
    "    min_samples=HDBSCAN_MIN_SAMPLES,\n",
    "    metric=\"euclidean\",\n",
    "    cluster_selection_method=\"eom\",\n",
    ")\n",
    "\n",
    "labels = clusterer.fit_predict(X_umap)\n",
    "df[\"cluster_id\"] = labels\n",
    "\n",
    "print(df[\"cluster_id\"].value_counts().head(20))\n",
    "print(\"Number of clusters (excluding noise):\", len(set(labels) - {-1}))\n",
    "print(\"Number of noise points (label -1):\", np.sum(labels == -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55d31fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Helper to get representative texts per cluster\n",
    "\n",
    "def get_representatives_for_cluster(cluster_id: int, top_k: int = 30):\n",
    "    \"\"\"\n",
    "    Return up to top_k representative texts from a given cluster,\n",
    "    ordered by similarity to the cluster centroid in UMAP space.\n",
    "    \"\"\"\n",
    "    mask = df[\"cluster_id\"] == cluster_id\n",
    "    idx = np.where(mask.values)[0]\n",
    "    if len(idx) == 0:\n",
    "        return []\n",
    "\n",
    "    cluster_vecs = X_umap[idx]\n",
    "    centroid = cluster_vecs.mean(axis=0)\n",
    "\n",
    "    scores = cluster_vecs @ centroid\n",
    "    order = np.argsort(-scores)\n",
    "    top_idx = idx[order[:top_k]]\n",
    "\n",
    "    reps = df.loc[top_idx, \"text\"].astype(str).tolist()\n",
    "    return reps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0da3b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: LLM helper to label clusters\n",
    "\n",
    "def llm_label_cluster(cluster_id: int, example_texts, max_chars: int = 4000):\n",
    "    \"\"\"\n",
    "    Ask OpenAI to propose a short name and summary for a cluster.\n",
    "    \"\"\"\n",
    "    if not example_texts:\n",
    "        return f\"Cluster {cluster_id}\", \"No representative examples available.\"\n",
    "\n",
    "    combined = \"\\n\\n\".join(example_texts)\n",
    "    combined = combined[:max_chars]\n",
    "\n",
    "    system_msg = (\n",
    "        \"You are given example paragraphs that belong to the same semantic cluster from a larger corpus. \\n\"\n",
    "        \"Your task:\\n\"\n",
    "        \"1) Provide a short descriptive cluster name (max 8 words)\\n\"\n",
    "        \"2) Provide a concise 3 sentence summary of the main theme\\n\"\n",
    "        \"Respond ONLY in JSON with keys: cluster_name, cluster_summary.\"\n",
    "    )\n",
    "\n",
    "    user_msg = f\"Cluster ID: {cluster_id}\\n\\nExample paragraphs:\\n\\n{combined}\"\n",
    "\n",
    "    resp = client.chat.completions.create(\n",
    "        model=OPENAI_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "    )\n",
    "\n",
    "    data = json.loads(resp.choices[0].message.content)\n",
    "    cluster_name = data.get(\"cluster_name\", f\"Cluster {cluster_id}\")\n",
    "    cluster_summary = data.get(\"cluster_summary\", \"\")\n",
    "    return cluster_name, cluster_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a4f3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -> Cooperative Property Transactions\n",
      "1 -> Condominium Sales and Valuations\n",
      "2 -> Residential Property Identifiers and Details\n",
      "3 -> Political Discussions and Economic Views\n",
      "4 -> Real Estate Transactions and Investments\n",
      "5 -> Real Estate Transaction Records\n",
      "6 -> U.S. Anti-Terrorism Laws and Enforcement\n",
      "7 -> Snowden, NSA, and Media Collaboration\n",
      "8 -> Reality TV Shows and Media\n",
      "9 -> Political News and Developments\n",
      "10 -> Military Operations and Tactical Planning\n",
      "11 -> Culinary Disasters and Life Lessons\n",
      "12 -> Victims' Rights in Presentence Reports\n",
      "13 -> FCPA Compliance and Successor Liability\n",
      "14 -> Safety and Violence in Urban India\n",
      "15 -> Sexual Consent and Communication\n",
      "16 -> U.S. Tax Implications for Investment Funds\n",
      "17 -> Government Fiscal Policies and Medicare Liabilities\n",
      "18 -> Dictatorship, Democracy, and Social Change\n",
      "19 -> Analysis of Warfare and Disease Propagation\n",
      "20 -> Behavioral Responses to Psychological Changes\n",
      "21 -> Nonlinear Dynamics in Neuroscience and Physiology\n",
      "22 -> Legal Communication and Oversight\n",
      "23 -> Freedom of Speech and Privacy Rights\n",
      "24 -> Presidential Authority and Constitutional Balance\n",
      "25 -> Legal Proceedings Transcript\n",
      "26 -> Epstein's Social Circle and Dynamics\n",
      "27 -> Legal Proceedings and Attorneys Involved\n",
      "28 -> Allegations Against Trump\n",
      "29 -> Allegations Against High-Profile Individuals\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_name</th>\n",
       "      <th>cluster_summary</th>\n",
       "      <th>num_examples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Cooperative Property Transactions</td>\n",
       "      <td>This cluster contains details about various tr...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Condominium Sales and Valuations</td>\n",
       "      <td>This cluster provides a detailed accounting of...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Residential Property Identifiers and Details</td>\n",
       "      <td>This cluster contains a series of residential ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Political Discussions and Economic Views</td>\n",
       "      <td>The messages focus on discussions surrounding ...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Real Estate Transactions and Investments</td>\n",
       "      <td>This cluster highlights numerous real estate t...</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id                                  cluster_name  \\\n",
       "0           0             Cooperative Property Transactions   \n",
       "1           1              Condominium Sales and Valuations   \n",
       "2           2  Residential Property Identifiers and Details   \n",
       "3           3      Political Discussions and Economic Views   \n",
       "4           4      Real Estate Transactions and Investments   \n",
       "\n",
       "                                     cluster_summary  num_examples  \n",
       "0  This cluster contains details about various tr...            25  \n",
       "1  This cluster provides a detailed accounting of...            25  \n",
       "2  This cluster contains a series of residential ...            25  \n",
       "3  The messages focus on discussions surrounding ...            25  \n",
       "4  This cluster highlights numerous real estate t...            25  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 9: Label all clusters with OpenAI and merge\n",
    "\n",
    "cluster_labels = []\n",
    "max_examples_per_cluster = 25  # tune for cost / quality\n",
    "\n",
    "unique_clusters = sorted(c for c in df[\"cluster_id\"].unique() if c != -1)\n",
    "\n",
    "for cid in unique_clusters:\n",
    "    examples = get_representatives_for_cluster(cid, top_k=max_examples_per_cluster)\n",
    "    if not examples:\n",
    "        cluster_name = f\"Cluster {cid}\"\n",
    "        cluster_summary = \"No representative examples available.\"\n",
    "    else:\n",
    "        cluster_name, cluster_summary = llm_label_cluster(cid, examples)\n",
    "\n",
    "    cluster_labels.append(\n",
    "        {\n",
    "            \"cluster_id\": cid,\n",
    "            \"cluster_name\": cluster_name,\n",
    "            \"cluster_summary\": cluster_summary,\n",
    "            \"num_examples\": len(examples),\n",
    "        }\n",
    "    )\n",
    "    print(cid, \"->\", cluster_name)\n",
    "\n",
    "# For noise cluster -1, you can optionally add a default label\n",
    "if -1 in df[\"cluster_id\"].unique():\n",
    "    cluster_labels.append(\n",
    "        {\n",
    "            \"cluster_id\": -1,\n",
    "            \"cluster_name\": \"Noise / Misc\",\n",
    "            \"cluster_summary\": \"Outlier or weakly clustered chunks.\",\n",
    "            \"num_examples\": int((df['cluster_id'] == -1).sum()),\n",
    "        }\n",
    "    )\n",
    "\n",
    "cluster_labels_df = pd.DataFrame(cluster_labels)\n",
    "cluster_labels_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46f25ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      chunk_id  doc_id  cluster_id  \\\n",
      "0  016697_c937  016697           2   \n",
      "1  023731_c153  023731          11   \n",
      "2  027333_c015  027333           3   \n",
      "3  025231_c005  025231          22   \n",
      "4  017088_c153  017088          23   \n",
      "\n",
      "                                   cluster_name  \n",
      "0  Residential Property Identifiers and Details  \n",
      "1           Culinary Disasters and Life Lessons  \n",
      "2      Political Discussions and Economic Views  \n",
      "3             Legal Communication and Oversight  \n",
      "4          Freedom of Speech and Privacy Rights  \n",
      "Saved CSV: chunks_with_hdbscan_clusters_and_labels_from_weaviate_HDBSCAN.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Join labels onto df and save\n",
    "\n",
    "df = df.merge(cluster_labels_df, on=\"cluster_id\", how=\"left\")\n",
    "\n",
    "print(df[[\"chunk_id\", \"doc_id\", \"cluster_id\", \"cluster_name\"]].head())\n",
    "\n",
    "OUT_CSV = \"chunks_with_hdbscan_clusters_and_labels_from_weaviate_HDBSCAN.csv\"\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(\"Saved CSV:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa5c95-29e5-4f56-bdd9-cedeb180177b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
